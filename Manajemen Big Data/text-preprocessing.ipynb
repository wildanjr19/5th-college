{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f9bf05",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b610af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/AliceInWonderland_Ch01.txt', 'r', encoding = 'utf-8') as f:\n",
    "    docs = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6351d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total karakter: 11385\n"
     ]
    }
   ],
   "source": [
    "# total karakter\n",
    "print(\"Total karakter:\", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605b007",
   "metadata": {},
   "source": [
    "# Token Awal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d569a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token awal: 2615\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token_awal = word_tokenize(docs)\n",
    "print(\"Token awal:\", len(token_awal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d23d4",
   "metadata": {},
   "source": [
    "# REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f85099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5057ec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank and of having nothing to do once or twice she had peeped into\n",
      "the book her sister was reading but it had no pictures or\n",
      "conversations in it “and what is the use of a book” thought Alice\n",
      "“without pictures or conversations”\n",
      "\n",
      "So she was considering in her own mind as well as she could for the\n",
      "hot day made her feel very sleepy and stupid whether the pleasure of\n",
      "making a daisychain would be worth the trouble of getting up and\n",
      "picking the daisies when suddenly a White Rabbit with pink eyes ran\n",
      "close by her\n",
      "\n",
      "There was nothing so very remarkable in that nor did Alice think it\n",
      "so very much out of the way to hear the Rabbit say to itself “Oh\n",
      "dear Oh dear I shall be late” when she thought it over afterwards\n",
      "it occurred to her that she ought to have wondered at this but at the\n",
      "time it all seemed quite natural but when the Rabbit actually took a\n",
      "watch out of its waistcoatpocket and looked at it and then hurried\n",
      "on Alice started to her feet for it flashed across her mind that she\n",
      "had never before seen a rabbit with either a waistcoatpocket or a\n",
      "watch to take out of it and burning with curiosity she ran across the\n",
      "field after it and fortunately was just in time to see it pop down a\n",
      "large rabbithole under the hedge\n",
      "\n",
      "In another moment down went Alice after it never once considering how\n",
      "in the world she was to get out again\n",
      "\n",
      "The rabbithole went straight on like a tunnel for some way and then\n",
      "dipped suddenly down so suddenly that Alice had not a moment to think\n",
      "about stopping herself before she found herself falling down a very\n",
      "deep well\n",
      "\n",
      "Either the well was very deep or she fell very slowly for she had\n",
      "plenty of time as she went down to look about her and to wonder what\n",
      "was going to happen next First she tried to look down and make out\n",
      "what she was coming to but it was too dark to see anything then she\n",
      "looked at the sides of the well and noticed that they were filled with\n",
      "cupboards and bookshelves here and there she saw maps and pictures\n",
      "hung upon pegs She took down a jar from one of the shelves as she\n",
      "passed it was labelled “ORANGE MARMALADE” but to her great\n",
      "disappointment it was empty she did not like to drop the jar for fear\n",
      "of killing somebody underneath so managed to put it into one of the\n",
      "cupboards as she fell past it\n",
      "\n",
      "“Well” thought Alice to herself “after such a fall as this I shall\n",
      "think nothing of tumbling down stairs How brave they’ll all think me\n",
      "at home Why I wouldn’t say anything about it even if I fell off the\n",
      "top of the house” Which was very likely true\n",
      "\n",
      "Down down down Would the fall never come to an end “I wonder how\n",
      "many miles I’ve fallen by this time” she said aloud “I must be\n",
      "getting somewhere near the centre of the earth Let me see that would\n",
      "be four thousand miles down I think—” for you see Alice had learnt\n",
      "several things of this sort in her lessons in the schoolroom and\n",
      "though this was not a very good opportunity for showing off her\n",
      "knowledge as there was no one to listen to her still it was good\n",
      "practice to say it over “—yes that’s about the right distance—but\n",
      "then I wonder what Latitude or Longitude I’ve got to” Alice had no\n",
      "idea what Latitude was or Longitude either but thought they were nice\n",
      "grand words to say\n",
      "\n",
      "Presently she began again “I wonder if I shall fall right through\n",
      "the earth How funny it’ll seem to come out among the people that walk\n",
      "with their heads downward The Antipathies I think—” she was rather\n",
      "glad there was no one listening this time as it didn’t sound at all\n",
      "the right word “—but I shall have to ask them what the name of the\n",
      "country is you know Please Ma’am is this New Zealand or Australia”\n",
      "and she tried to curtsey as she spoke—fancy curtseying as you’re\n",
      "falling through the air Do you think you could manage it “And what\n",
      "an ignorant little girl she’ll think me for asking No it’ll never do\n",
      "to ask perhaps I shall see it written up somewhere”\n",
      "\n",
      "Down down down There was nothing else to do so Alice soon began\n",
      "talking again “Dinah’ll miss me very much tonight I should think”\n",
      "Dinah was the cat “I hope they’ll remember her saucer of milk at\n",
      "teatime Dinah my dear I wish you were down here with me There are\n",
      "no mice in the air I’m afraid but you might catch a bat and that’s\n",
      "very like a mouse you know But do cats eat bats I wonder” And here\n",
      "Alice began to get rather sleepy and went on saying to herself in a\n",
      "dreamy sort of way “Do cats eat bats Do cats eat bats” and\n",
      "sometimes “Do bats eat cats” for you see as she couldn’t answer\n",
      "either question it didn’t much matter which way she put it She felt\n",
      "that she was dozing off and had just begun to dream that she was\n",
      "walking hand in hand with Dinah and saying to her very earnestly\n",
      "“Now Dinah tell me the truth did you ever eat a bat” when suddenly\n",
      "thump thump down she came upon a heap of sticks and dry leaves and\n",
      "the fall was over\n",
      "\n",
      "Alice was not a bit hurt and she jumped up on to her feet in a moment\n",
      "she looked up but it was all dark overhead before her was another\n",
      "long passage a\n"
     ]
    }
   ],
   "source": [
    "# hapus titik, koma, dan tanda baca lainnya\n",
    "new_docs = docs.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "print(new_docs[:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a144f0",
   "metadata": {},
   "source": [
    "“without pictures or conversations” dsb, tidak ikut dibersihkan karena bukan ASCII "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472abb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8979285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank and of having nothing to do once or twice she had peeped into\n",
      "the book her sister was reading but it had no pictures or\n",
      "conversations in it and what is the use of a book thought Alice\n",
      "without pictures or conversations\n",
      "\n",
      "So she was considering in her own mind as well as she could for the\n",
      "hot day made her feel very sleepy and stupid whether the pleasure of\n",
      "making a daisychain would be worth the trouble of getting up and\n",
      "picking the daisies when suddenly a White Rabbit with pink eyes ran\n",
      "close by her\n",
      "\n",
      "There was nothing so very remarkable in that nor did Alice think it\n",
      "so very much out of the way to hear the Rabbit say to itself Oh\n",
      "dear Oh dear I shall be late when she thought it over afterwards\n",
      "it occurred to her that she ought to have wondered at this but at the\n",
      "time it all seemed quite natural but when the Rabbit actually took a\n",
      "watch out of its waistcoatpocket and looked at it and then hurried\n",
      "on Alice started to her feet for it flashed across her mind that she\n",
      "had never before seen a rabbit with either a waistcoatpocket or a\n",
      "watch to take out of it and burning with curiosity she ran across the\n",
      "field after it and fortunately was just in time to see it pop down a\n",
      "large rabbithole under the hedge\n",
      "\n",
      "In another moment down went Alice after it never once considering how\n",
      "in the world she was to get out again\n",
      "\n",
      "The rabbithole went straight on like a tunnel for some way and then\n",
      "dipped suddenly down so suddenly that Alice had not a moment to think\n",
      "about stopping herself before she found herself falling down a very\n",
      "deep well\n",
      "\n",
      "Either the well was very deep or she fell very slowly for she had\n",
      "plenty of time as she went down to look about her and to wonder what\n",
      "was going to happen next First she tried to look down and make out\n",
      "what she was coming to but it was too dark to see anything then she\n",
      "looked at the sides of the well and noticed that they were filled with\n",
      "cupboards and bookshelves here and there she saw maps and pictures\n",
      "hung upon pegs She took down a jar from one of the shelves as she\n",
      "passed it was labelled ORANGE MARMALADE but to her great\n",
      "disappointment it was empty she did not like to drop the jar for fear\n",
      "of killing somebody underneath so managed to put it into one of the\n",
      "cupboards as she fell past it\n",
      "\n",
      "Well thought Alice to herself after such a fall as this I shall\n",
      "think nothing of tumbling down stairs How brave theyll all think me\n",
      "at home Why I wouldnt say anything about it even if I fell off the\n",
      "top of the house Which was very likely true\n",
      "\n",
      "Down down down Would the fall never come to an end I wonder how\n",
      "many miles Ive fallen by this time she said aloud I must be\n",
      "getting somewhere near the centre of the earth Let me see that would\n",
      "be four thousand miles down I think for you see Alice had learnt\n",
      "several things of this sort in her lessons in the schoolroom and\n",
      "though this was not a very good opportunity for showing off her\n",
      "knowledge as there was no one to listen to her still it was good\n",
      "practice to say it over yes thats about the right distancebut\n",
      "then I wonder what Latitude or Longitude Ive got to Alice had no\n",
      "idea what Latitude was or Longitude either but thought they were nice\n",
      "grand words to say\n",
      "\n",
      "Presently she began again I wonder if I shall fall right through\n",
      "the earth How funny itll seem to come out among the people that walk\n",
      "with their heads downward The Antipathies I think she was rather\n",
      "glad there was no one listening this time as it didnt sound at all\n",
      "the right word but I shall have to ask them what the name of the\n",
      "country is you know Please Maam is this New Zealand or Australia\n",
      "and she tried to curtsey as she spokefancy curtseying as youre\n",
      "falling through the air Do you think you could manage it And what\n",
      "an ignorant little girl shell think me for asking No itll never do\n",
      "to ask perhaps I shall see it written up somewhere\n",
      "\n",
      "Down down down There was nothing else to do so Alice soon began\n",
      "talking again Dinahll miss me very much tonight I should think\n",
      "Dinah was the cat I hope theyll remember her saucer of milk at\n",
      "teatime Dinah my dear I wish you were down here with me There are\n",
      "no mice in the air Im afraid but you might catch a bat and thats\n",
      "very like a mouse you know But do cats eat bats I wonder And here\n",
      "Alice began to get rather sleepy and went on saying to herself in a\n",
      "dreamy sort of way Do cats eat bats Do cats eat bats and\n",
      "sometimes Do bats eat cats for you see as she couldnt answer\n",
      "either question it didnt much matter which way she put it She felt\n",
      "that she was dozing off and had just begun to dream that she was\n",
      "walking hand in hand with Dinah and saying to her very earnestly\n",
      "Now Dinah tell me the truth did you ever eat a bat when suddenly\n",
      "thump thump down she came upon a heap of sticks and dry leaves and\n",
      "the fall was over\n",
      "\n",
      "Alice was not a bit hurt and she jumped up on to her feet in a moment\n",
      "she looked up but it was all dark overhead before her was another\n",
      "long passage and the White Rabbit was still in sight hurrying down\n",
      "it T\n"
     ]
    }
   ],
   "source": [
    "# hapus tanda baca yang lain \n",
    "# termasuk yang bukan ASCII\n",
    "new_docs = re.sub(r'[^\\w\\s]', '', new_docs)\n",
    "print(new_docs[:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875badc",
   "metadata": {},
   "source": [
    "# STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26158c72",
   "metadata": {},
   "source": [
    "Kata yang berdiri sendiri dan tidak ada maknanya, seperti kata hubung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4ee747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5b04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import english stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# gunakan stopwords bahasa inggris\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# tokenisasi\n",
    "word_tokens = word_tokenize(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003dccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply stopword \n",
    "filtered_docs = [word for word in word_tokens if not word.lower() in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0de0a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice beginning get tired sitting sister bank nothing twice peeped book sister reading pictures conversations use book thought Alice without pictures conversations considering mind well could hot day made feel sleepy stupid whether pleasure making daisychain would worth trouble getting picking daisies suddenly White Rabbit pink eyes ran close nothing remarkable Alice think much way hear Rabbit say Oh dear Oh dear shall late thought afterwards occurred ought wondered time seemed quite natural Rabbit actually took watch waistcoatpocket looked hurried Alice started feet flashed across mind never seen rabbit either waistcoatpocket watch take burning curiosity ran across field fortunately time see pop large rabbithole hedge another moment went Alice never considering world get rabbithole went straight like tunnel way dipped suddenly suddenly Alice moment think stopping found falling deep well Either well deep fell slowly plenty time went look wonder going happen next First tried look make coming dark see anything looked sides well noticed filled cupboards bookshelves saw maps pictures hung upon pegs took jar one shelves passed labelled ORANGE MARMALADE great disappointment empty like drop jar fear killing somebody underneath managed put one cupboards fell past Well thought Alice fall shall think nothing tumbling stairs brave theyll think\n"
     ]
    }
   ],
   "source": [
    "# print\n",
    "print(\" \".join(filtered_docs[:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf353a05",
   "metadata": {},
   "source": [
    "Kata seperti 'was' dihapus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf888c07",
   "metadata": {},
   "source": [
    "# LOWERCASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a550943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'alice', 'without', 'pictures', 'conversations', 'considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisychain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close', 'nothing', 'remarkable', 'alice', 'think', 'much', 'way', 'hear', 'rabbit', 'say', 'oh', 'dear', 'oh', 'dear', 'shall', 'late', 'thought', 'afterwards', 'occurred', 'ought', 'wondered', 'time', 'seemed', 'quite', 'natural', 'rabbit', 'actually', 'took', 'watch', 'waistcoatpocket', 'looked', 'hurried', 'alice', 'started', 'feet', 'flashed', 'across', 'mind', 'never', 'seen', 'rabbit', 'either', 'waistcoatpocket', 'watch', 'take', 'burning', 'curiosity', 'ran', 'across', 'field', 'fortunately', 'time', 'see', 'pop', 'large', 'rabbithole', 'hedge', 'another', 'moment', 'went', 'alice', 'never', 'considering', 'world', 'get', 'rabbithole', 'went', 'straight', 'like', 'tunnel', 'way', 'dipped', 'suddenly', 'suddenly', 'alice', 'moment', 'think', 'stopping', 'found', 'falling', 'deep', 'well', 'either', 'well', 'deep', 'fell', 'slowly', 'plenty', 'time', 'went', 'look', 'wonder', 'going', 'happen', 'next', 'first', 'tried', 'look', 'make', 'coming', 'dark', 'see', 'anything', 'looked', 'sides', 'well', 'noticed', 'filled', 'cupboards', 'bookshelves', 'saw', 'maps', 'pictures', 'hung', 'upon', 'pegs', 'took', 'jar', 'one', 'shelves', 'passed', 'labelled', 'orange', 'marmalade', 'great', 'disappointment', 'empty', 'like', 'drop', 'jar', 'fear', 'killing', 'somebody', 'underneath', 'managed', 'put', 'one', 'cupboards', 'fell', 'past', 'well', 'thought', 'alice', 'fall', 'shall', 'think', 'nothing', 'tumbling', 'stairs', 'brave', 'theyll', 'think', 'home', 'wouldnt', 'say', 'anything', 'even', 'fell', 'top', 'house', 'likely', 'true', 'would', 'fall', 'never', 'come', 'end', 'wonder', 'many', 'miles', 'ive', 'fallen', 'time', 'said', 'aloud', 'must', 'getting', 'somewhere', 'near', 'centre', 'earth', 'let', 'see', 'would', 'four', 'thousand', 'miles', 'think', 'see', 'alice', 'learnt', 'several', 'things', 'sort', 'lessons', 'schoolroom', 'though', 'good', 'opportunity', 'showing', 'knowledge', 'one', 'listen', 'still', 'good', 'practice', 'say', 'yes', 'thats', 'right', 'distancebut', 'wonder', 'latitude', 'longitude', 'ive', 'got', 'alice', 'idea', 'latitude', 'longitude', 'either', 'thought', 'nice', 'grand', 'words', 'say', 'presently', 'began', 'wonder', 'shall', 'fall', 'right', 'earth', 'funny', 'itll', 'seem', 'come', 'among', 'people', 'walk', 'heads', 'downward', 'antipathies', 'think', 'rather', 'glad', 'one', 'listening', 'time', 'didnt', 'sound', 'right', 'word', 'shall', 'ask', 'name', 'country', 'know', 'please', 'maam', 'new', 'zealand', 'australia', 'tried', 'curtsey', 'spokefancy', 'curtseying', 'youre', 'falling', 'air', 'think', 'could', 'manage', 'ignorant', 'little', 'girl', 'shell', 'think', 'asking', 'itll', 'never', 'ask', 'perhaps', 'shall', 'see', 'written', 'somewhere', 'nothing', 'else', 'alice', 'soon', 'began', 'talking', 'dinahll', 'miss', 'much', 'tonight', 'think', 'dinah', 'cat', 'hope', 'theyll', 'remember', 'saucer', 'milk', 'teatime', 'dinah', 'dear', 'wish', 'mice', 'air', 'im', 'afraid', 'might', 'catch', 'bat', 'thats', 'like', 'mouse', 'know', 'cats', 'eat', 'bats', 'wonder', 'alice', 'began', 'get', 'rather', 'sleepy', 'went', 'saying', 'dreamy', 'sort', 'way', 'cats', 'eat', 'bats', 'cats', 'eat', 'bats', 'sometimes', 'bats', 'eat', 'cats', 'see', 'couldnt', 'answer', 'either', 'question', 'didnt', 'much', 'matter', 'way', 'put', 'felt', 'dozing', 'begun', 'dream', 'walking', 'hand', 'hand', 'dinah', 'saying', 'earnestly', 'dinah', 'tell', 'truth', 'ever', 'eat', 'bat', 'suddenly', 'thump', 'thump', 'came', 'upon', 'heap', 'sticks', 'dry', 'leaves', 'fall', 'alice', 'bit', 'hurt', 'jumped', 'feet', 'moment', 'looked', 'dark', 'overhead', 'another', 'long', 'passage', 'white', 'rabbit', 'still', 'sight', 'hurrying', 'moment', 'lost', 'away', 'went', 'alice', 'like', 'wind', 'time', 'hear', 'say', 'turned', 'corner', 'oh', 'ears', 'whiskers', 'late', 'getting', 'close', 'behind', 'turned', 'corner', 'rabbit', 'longer', 'seen', 'found', 'long', 'low', 'hall', 'lit', 'row', 'lamps', 'hanging', 'roof', 'doors', 'round', 'hall', 'locked', 'alice', 'way', 'one', 'side', 'trying', 'every', 'door', 'walked', 'sadly', 'middle', 'wondering', 'ever', 'get', 'suddenly', 'came', 'upon', 'little', 'threelegged', 'table', 'made', 'solid', 'glass', 'nothing', 'except', 'tiny', 'golden', 'key', 'alices', 'first', 'thought', 'might', 'belong', 'one', 'doors', 'hall', 'alas', 'either', 'locks', 'large', 'key', 'small', 'rate', 'would', 'open', 'however', 'second', 'time', 'round', 'came', 'upon', 'low', 'curtain', 'noticed', 'behind', 'little', 'door', 'fifteen', 'inches', 'high', 'tried', 'little', 'golden', 'key', 'lock', 'great', 'delight', 'fitted', 'alice', 'opened', 'door', 'found', 'led', 'small', 'passage', 'much', 'larger', 'rathole', 'knelt', 'looked', 'along', 'passage', 'loveliest', 'garden', 'ever', 'saw', 'longed', 'get', 'dark', 'hall', 'wander', 'among', 'beds', 'bright', 'flowers', 'cool', 'fountains', 'could', 'even', 'get', 'head', 'doorway', 'even', 'head', 'would', 'go', 'thought', 'poor', 'alice', 'would', 'little', 'use', 'without', 'shoulders', 'oh', 'wish', 'could', 'shut', 'like', 'telescope', 'think', 'could', 'knew', 'begin', 'see', 'many', 'outoftheway', 'things', 'happened', 'lately', 'alice', 'begun', 'think', 'things', 'indeed', 'really', 'impossible', 'seemed', 'use', 'waiting', 'little', 'door', 'went', 'back', 'table', 'half', 'hoping', 'might', 'find', 'another', 'key', 'rate', 'book', 'rules', 'shutting', 'people', 'like', 'telescopes', 'time', 'found', 'little', 'bottle', 'certainly', 'said', 'alice', 'round', 'neck', 'bottle', 'paper', 'label', 'words', 'drink', 'beautifully', 'printed', 'large', 'letters', 'well', 'say', 'drink', 'wise', 'little', 'alice', 'going', 'hurry', 'ill', 'look', 'first', 'said', 'see', 'whether', 'marked', 'poison', 'read', 'several', 'nice', 'little', 'histories', 'children', 'got', 'burnt', 'eaten', 'wild', 'beasts', 'unpleasant', 'things', 'would', 'remember', 'simple', 'rules', 'friends', 'taught', 'redhot', 'poker', 'burn', 'hold', 'long', 'cut', 'finger', 'deeply', 'knife', 'usually', 'bleeds', 'never', 'forgotten', 'drink', 'much', 'bottle', 'marked', 'poison', 'almost', 'certain', 'disagree', 'sooner', 'later', 'however', 'bottle', 'marked', 'poison', 'alice', 'ventured', 'taste', 'finding', 'nice', 'fact', 'sort', 'mixed', 'flavour', 'cherrytart', 'custard', 'pineapple', 'roast', 'turkey', 'toffee', 'hot', 'buttered', 'toast', 'soon', 'finished', 'curious', 'feeling', 'said', 'alice', 'must', 'shutting', 'like', 'telescope', 'indeed', 'ten', 'inches', 'high', 'face', 'brightened', 'thought', 'right', 'size', 'going', 'little', 'door', 'lovely', 'garden', 'first', 'however', 'waited', 'minutes', 'see', 'going', 'shrink', 'felt', 'little', 'nervous', 'might', 'end', 'know', 'said', 'alice', 'going', 'altogether', 'like', 'candle', 'wonder', 'like', 'tried', 'fancy', 'flame', 'candle', 'like', 'candle', 'blown', 'could', 'remember', 'ever', 'seen', 'thing', 'finding', 'nothing', 'happened', 'decided', 'going', 'garden', 'alas', 'poor', 'alice', 'got', 'door', 'found', 'forgotten', 'little', 'golden', 'key', 'went', 'back', 'table', 'found', 'could', 'possibly', 'reach', 'could', 'see', 'quite', 'plainly', 'glass', 'tried', 'best', 'climb', 'one', 'legs', 'table', 'slippery', 'tired', 'trying', 'poor', 'little', 'thing', 'sat', 'cried', 'come', 'theres', 'use', 'crying', 'like', 'said', 'alice', 'rather', 'sharply', 'advise', 'leave', 'minute', 'generally', 'gave', 'good', 'advice', 'though', 'seldom', 'followed', 'sometimes', 'scolded', 'severely', 'bring', 'tears', 'eyes', 'remembered', 'trying', 'box', 'ears', 'cheated', 'game', 'croquet', 'playing', 'curious', 'child', 'fond', 'pretending', 'two', 'people', 'use', 'thought', 'poor', 'alice', 'pretend', 'two', 'people', 'theres', 'hardly', 'enough', 'left', 'make', 'one', 'respectable', 'person', 'soon', 'eye', 'fell', 'little', 'glass', 'box', 'lying', 'table', 'opened', 'found', 'small', 'cake', 'words', 'eat', 'beautifully', 'marked', 'currants', 'well', 'ill', 'eat', 'said', 'alice', 'makes', 'grow', 'larger', 'reach', 'key', 'makes', 'grow', 'smaller', 'creep', 'door', 'either', 'way', 'ill', 'get', 'garden', 'dont', 'care', 'happens', 'ate', 'little', 'bit', 'said', 'anxiously', 'way', 'way', 'holding', 'hand', 'top', 'head', 'feel', 'way', 'growing', 'quite', 'surprised', 'find', 'remained', 'size', 'sure', 'generally', 'happens', 'one', 'eats', 'cake', 'alice', 'got', 'much', 'way', 'expecting', 'nothing', 'outoftheway', 'things', 'happen', 'seemed', 'quite', 'dull', 'stupid', 'life', 'go', 'common', 'way', 'set', 'work', 'soon', 'finished', 'cake']\n"
     ]
    }
   ],
   "source": [
    "# mengubaah teks di filtered_docs menjadi lower semua\n",
    "# karena bentuknya list maka gunakan list comprehension\n",
    "lowered_docs = [word.lower() for word in filtered_docs]\n",
    "print(lowered_docs[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09590048",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mengubah teks menjadi lower semua\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lowered_docs \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_docs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(lowered_docs[:\u001b[38;5;241m5000\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# mengubah teks menjadi lower semua\n",
    "lowered_docs = filtered_docs.lower()\n",
    "print(lowered_docs[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07341285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuk checkpoint, simpan hasil preprocessing ke file\n",
    "with open('data/preprocessed_AliceInWonderland_Ch01.txt', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(\" \".join(filtered_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f386317",
   "metadata": {},
   "source": [
    "# TRANSFORMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d6100a",
   "metadata": {},
   "source": [
    "Untuk transformers lanjut di collab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82d21e",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d03a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99240f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# karena bentuknya list maka gunakan list comprehension\n",
    "# tokenisasi dulu\n",
    "words = word_tokenize(\" \".join(lowered_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97827483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alic begin get tire sit sister bank noth twice peep book sister read pictur convers use book thought alic without pictur convers consid mind well could hot day made feel sleepi stupid whether pleasur make daisychain would worth troubl get pick daisi suddenli white rabbit pink eye ran close noth remark alic think much way hear rabbit say oh dear oh dear shall late thought afterward occur ought wonder time seem quit natur rabbit actual took watch waistcoatpocket look hurri alic start feet flash across mind never seen rabbit either waistcoatpocket watch take burn curios ran across field fortun time see pop larg rabbithol hedg anoth moment went alic never consid world get rabbithol went straight like tunnel way dip suddenli suddenli alic moment think stop found fall deep well either well deep fell slowli plenti time went look wonder go happen next first tri look make come dark see anyth look side well notic fill cupboard bookshelv saw map pictur hung upon peg took jar one shelv pass label orang marmalad great disappoint empti like drop jar fear kill somebodi underneath manag put one cupboard fell past well thought alic fall shall think noth tumbl stair brave theyll think home wouldnt say anyth even fell top hous like true would fall never come end wonder mani mile ive fallen time said aloud must get somewher near centr earth let see would four thousand mile think see alic learnt sever thing sort lesson schoolroom though good opportun show knowledg one listen still good practic say ye that right distancebut wonder latitud longitud ive got alic idea latitud longitud either thought nice grand word say present began wonder shall fall right earth funni itll seem come among peopl walk head downward antipathi think rather glad one listen time didnt sound right word shall ask name countri know pleas maam new zealand australia tri curtsey spokef curtsey your fall air think could manag ignor littl girl shell think ask itll never ask perhap shall see written somewher noth els alic soon began talk dinahl miss much tonight think dinah cat hope theyll rememb saucer milk teatim dinah dear wish mice air im afraid might catch bat that like mous know cat eat bat wonder alic began get rather sleepi went say dreami sort way cat eat bat cat eat bat sometim bat eat cat see couldnt answer either question didnt much matter way put felt doze begun dream walk hand hand dinah say earnestli dinah tell truth ever eat bat suddenli thump thump came upon heap stick dri leav fall alic bit hurt jump feet moment look dark overhead anoth long passag white rabbit still sight hurri moment lost away went alic like wind time hear say turn corner oh ear whisker late get close behind turn corner rabbit longer seen found long low hall lit row lamp hang roof door round hall lock alic way one side tri everi door walk sadli middl wonder ever get suddenli came upon littl threeleg\n"
     ]
    }
   ],
   "source": [
    "new_text = []\n",
    "for w in words:\n",
    "    new_text.append(ps.stem(w))\n",
    "\n",
    "print(\" \".join(new_text[:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f2b7b",
   "metadata": {},
   "source": [
    "# LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d153360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7410bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7ae098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice beginning get tired sitting sister bank nothing twice peeped book sister reading picture conversation use book thought alice without picture conversation considering mind well could hot day made feel sleepy stupid whether pleasure making daisychain would worth trouble getting picking daisy suddenly white rabbit pink eye ran close nothing remarkable alice think much way hear rabbit say oh dear oh dear shall late thought afterwards occurred ought wondered time seemed quite natural rabbit act\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(\" \".join(lowered_docs))\n",
    "new_text = \" \".join([wnl.lemmatize(w) for w in words])\n",
    "print(new_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f82e4b",
   "metadata": {},
   "source": [
    "# TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6773efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'alice', 'without', 'pictures', 'conversations', 'considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisychain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close', 'nothing', 'remarkable', 'alice', 'think', 'much', 'way', 'hear', 'rabbit', 'say', 'oh', 'dear', 'oh', 'dear', 'shall', 'late', 'thought', 'afterwards', 'occurred', 'ought', 'wondered', 'time', 'seemed', 'quite', 'natural', 'rabbit', 'actually', 'took', 'watch', 'waistcoatpocket', 'looked', 'hurried', 'alice', 'started', 'feet', 'flashed', 'across', 'mind', 'never', 'seen', 'rabbit', 'either', 'waistcoatpocket', 'watch', 'take', 'burning', 'curiosity', 'ran', 'across', 'field', 'fortunately', 'time', 'see', 'pop', 'large', 'rabbithole', 'hedge', 'another', 'moment', 'went', 'alice', 'never', 'considering', 'world', 'get', 'rabbithole', 'went', 'straight', 'like', 'tunnel', 'way', 'dipped', 'suddenly', 'suddenly', 'alice', 'moment', 'think', 'stopping', 'found', 'falling', 'deep', 'well', 'either', 'well', 'deep', 'fell', 'slowly', 'plenty', 'time', 'went', 'look', 'wonder', 'going', 'happen', 'next', 'first', 'tried', 'look', 'make', 'coming', 'dark', 'see', 'anything', 'looked', 'sides', 'well', 'noticed', 'filled', 'cupboards', 'bookshelves', 'saw', 'maps', 'pictures', 'hung', 'upon', 'pegs', 'took', 'jar', 'one', 'shelves', 'passed', 'labelled', 'orange', 'marmalade', 'great', 'disappointment', 'empty', 'like', 'drop', 'jar', 'fear', 'killing', 'somebody', 'underneath', 'managed', 'put', 'one', 'cupboards', 'fell', 'past', 'well', 'thought', 'alice', 'fall', 'shall', 'think', 'nothing', 'tumbling', 'stairs', 'brave', 'theyll', 'think', 'home', 'wouldnt', 'say', 'anything', 'even', 'fell', 'top', 'house', 'likely', 'true', 'would', 'fall', 'never', 'come', 'end', 'wonder', 'many', 'miles', 'ive', 'fallen', 'time', 'said', 'aloud', 'must', 'getting', 'somewhere', 'near', 'centre', 'earth', 'let', 'see', 'would', 'four', 'thousand', 'miles', 'think', 'see', 'alice', 'learnt', 'several', 'things', 'sort', 'lessons', 'schoolroom', 'though', 'good', 'opportunity', 'showing', 'knowledge', 'one', 'listen', 'still', 'good', 'practice', 'say', 'yes', 'thats', 'right', 'distancebut', 'wonder', 'latitude', 'longitude', 'ive', 'got', 'alice', 'idea', 'latitude', 'longitude', 'either', 'thought', 'nice', 'grand', 'words', 'say', 'presently', 'began', 'wonder', 'shall', 'fall', 'right', 'earth', 'funny', 'itll', 'seem', 'come', 'among', 'people', 'walk', 'heads', 'downward', 'antipathies', 'think', 'rather', 'glad', 'one', 'listening', 'time', 'didnt', 'sound', 'right', 'word', 'shall', 'ask', 'name', 'country', 'know', 'please', 'maam', 'new', 'zealand', 'australia', 'tried', 'curtsey', 'spokefancy', 'curtseying', 'youre', 'falling', 'air', 'think', 'could', 'manage', 'ignorant', 'little', 'girl', 'shell', 'think', 'asking', 'itll', 'never', 'ask', 'perhaps', 'shall', 'see', 'written', 'somewhere', 'nothing', 'else', 'alice', 'soon', 'began', 'talking', 'dinahll', 'miss', 'much', 'tonight', 'think', 'dinah', 'cat', 'hope', 'theyll', 'remember', 'saucer', 'milk', 'teatime', 'dinah', 'dear', 'wish', 'mice', 'air', 'im', 'afraid', 'might', 'catch', 'bat', 'thats', 'like', 'mouse', 'know', 'cats', 'eat', 'bats', 'wonder', 'alice', 'began', 'get', 'rather', 'sleepy', 'went', 'saying', 'dreamy', 'sort', 'way', 'cats', 'eat', 'bats', 'cats', 'eat', 'bats', 'sometimes', 'bats', 'eat', 'cats', 'see', 'couldnt', 'answer', 'either', 'question', 'didnt', 'much', 'matter', 'way', 'put', 'felt', 'dozing', 'begun', 'dream', 'walking', 'hand', 'hand', 'dinah', 'saying', 'earnestly', 'dinah', 'tell', 'truth', 'ever', 'eat', 'bat', 'suddenly', 'thump', 'thump', 'came', 'upon', 'heap', 'sticks', 'dry', 'leaves', 'fall', 'alice', 'bit', 'hurt', 'jumped', 'feet', 'moment', 'looked', 'dark', 'overhead', 'another', 'long', 'passage', 'white', 'rabbit', 'still', 'sight', 'hurrying', 'moment', 'lost', 'away', 'went', 'alice', 'like', 'wind', 'time', 'hear', 'say', 'turned', 'corner', 'oh', 'ears', 'whiskers', 'late', 'getting', 'close', 'behind', 'turned', 'corner', 'rabbit', 'longer', 'seen', 'found', 'long', 'low', 'hall', 'lit', 'row', 'lamps', 'hanging', 'roof', 'doors', 'round', 'hall', 'locked', 'alice', 'way', 'one', 'side', 'trying', 'every', 'door', 'walked', 'sadly', 'middle', 'wondering', 'ever', 'get', 'suddenly', 'came', 'upon', 'little', 'threelegged']\n"
     ]
    }
   ],
   "source": [
    "# tokenisasi\n",
    "data_tokenized = word_tokenize(\" \".join(lowered_docs))\n",
    "print(data_tokenized[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5d8b5",
   "metadata": {},
   "source": [
    "# token terakhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "060c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47c67c",
   "metadata": {},
   "source": [
    "# TEXT VECTORIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0083796",
   "metadata": {},
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418c47f",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f372c5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: and, One Hot Encoding: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Word: are, One Hot Encoding: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Word: cat, One Hot Encoding: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Word: cats, One Hot Encoding: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Word: dog, One Hot Encoding: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Word: dogs, One Hot Encoding: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Word: great, One Hot Encoding: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Word: log, One Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Word: mat, One Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Word: on, One Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Word: pets, One Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Word: sat, One Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Word: the, One Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog sat on the log\",\n",
    "    \"Cats and dogs are great pets.\"\n",
    "]\n",
    "\n",
    "words = [word.lower().strip(string.punctuation) for doc in documents for word in doc.split()]\n",
    "\n",
    "vocabulary = sorted(set(words))\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "one_hot_vectors = encoder.fit_transform(np.array(vocabulary).reshape(-1, 1))\n",
    "\n",
    "word_to_onehot = {vocabulary[i]: one_hot_vectors[i] for i in range(len(vocabulary))}\n",
    "\n",
    "for word, vector in word_to_onehot.items():\n",
    "    print(f\"Word: {word}, One Hot Encoding: {vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04806f94",
   "metadata": {},
   "source": [
    "### Terapkan ke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word.lower().strip(string.punctuation) for word in data_tokenized]\n",
    "vocabulary = sorted(set(words))\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "one_hot_vectors = encoder.fit_transform(np.array(vocabulary).reshape(-1, 1))\n",
    "\n",
    "word_to_onehot = {vocabulary[i]: one_hot_vectors[i] for i in range(len(vocabulary))}\n",
    "\n",
    "for word, vector in list(word_to_onehot.items())[:10]:\n",
    "    print(f\"Word: {word}, One Hot Encoding: {vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c5a9a9",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb17f33",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36e846",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "329e2b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 1 0 1 2]\n",
      " [0 0 0 0 1 0 1 0 1 0 1 2]\n",
      " [1 1 0 1 0 1 0 0 0 1 0 0]]\n",
      "['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'log' 'mat' 'on' 'pets' 'sat' 'the']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog sat on the log.\",\n",
    "    \"Cats and dogs are pets.\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(X.toarray())\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f21fd2",
   "metadata": {},
   "source": [
    "### Terapkan ke Data Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bd4add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1]]\n",
      "['alice' 'bank' 'beginning' 'book' 'conversations' 'get' 'nothing'\n",
      " 'peeped' 'pictures' 'reading' 'sister' 'sitting' 'thought' 'tired'\n",
      " 'twice' 'use' 'without']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([\" \".join(data_tokenized[:20])])\n",
    "\n",
    "print(X.toarray())\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa9280",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ee67e",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5c55d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.42755362 0.         0.         0.\n",
      "  0.         0.42755362 0.32516555 0.         0.32516555 0.6503311 ]\n",
      " [0.         0.         0.         0.         0.42755362 0.\n",
      "  0.42755362 0.         0.32516555 0.         0.32516555 0.6503311 ]\n",
      " [0.4472136  0.4472136  0.         0.4472136  0.         0.4472136\n",
      "  0.         0.         0.         0.4472136  0.         0.        ]]\n",
      "['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'log' 'mat' 'on' 'pets' 'sat' 'the']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog sat on the log.\",\n",
    "    \"Cats and dogs are pets.\"\n",
    "]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "print(X_tfidf.toarray())\n",
    "print(tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3d989",
   "metadata": {},
   "source": [
    "### Data Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f37309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39223227 0.19611614 0.19611614 0.39223227 0.19611614 0.19611614\n",
      "  0.19611614 0.19611614 0.19611614 0.19611614 0.39223227 0.19611614\n",
      "  0.19611614 0.19611614 0.19611614 0.19611614 0.19611614]]\n",
      "['alice' 'bank' 'beginning' 'book' 'conversations' 'get' 'nothing'\n",
      " 'peeped' 'pictures' 'reading' 'sister' 'sitting' 'thought' 'tired'\n",
      " 'twice' 'use' 'without']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform([\" \".join(data_tokenized[:20])])\n",
    "\n",
    "print(X.toarray())\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e3365",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195ad0d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48bef2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 1 0 1 2]\n",
      " [0 0 0 0 1 0 1 0 1 0 1 2]\n",
      " [1 1 0 1 0 1 0 0 0 1 0 0]]\n",
      "['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'log' 'mat' 'on' 'pets' 'sat' 'the']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog sat on the log.\",\n",
    "    \"Cats and dogs are pets.\"\n",
    "]\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_count = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "print(X_count.toarray())\n",
    "print(count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f63b8",
   "metadata": {},
   "source": [
    "### Data Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3a2479f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1]]\n",
      "['alice' 'bank' 'beginning' 'book' 'conversations' 'get' 'nothing'\n",
      " 'peeped' 'pictures' 'reading' 'sister' 'sitting' 'thought' 'tired'\n",
      " 'twice' 'use' 'without']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform([\" \".join(data_tokenized[:20])])\n",
    "\n",
    "print(X.toarray())\n",
    "print(count_vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
